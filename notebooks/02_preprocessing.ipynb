{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Imports and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path().resolve().parent\n",
    "\n",
    "train_FD001_data = pd.read_csv(project_root/'data/raw/CMAPSSData/train_FD001.txt', sep=' ', header=None)\n",
    "test_FD001_data = pd.read_csv(project_root/'data/raw/CMAPSSData/test_FD001.txt', sep=' ', header=None)\n",
    "\n",
    "train_FD002_data = pd.read_csv(project_root/'data/raw/CMAPSSData/train_FD002.txt', sep=' ', header=None)\n",
    "test_FD002_data = pd.read_csv(project_root/'data/raw/CMAPSSData/test_FD002.txt', sep=' ', header=None)\n",
    "\n",
    "train_FD003_data = pd.read_csv(project_root/'data/raw/CMAPSSData/train_FD003.txt', sep=' ', header=None)\n",
    "test_FD003_data = pd.read_csv(project_root/'data/raw/CMAPSSData/test_FD003.txt', sep=' ', header=None)\n",
    "\n",
    "train_FD004_data = pd.read_csv(project_root/'data/raw/CMAPSSData/train_FD004.txt', sep=' ', header=None)\n",
    "test_FD004_data = pd.read_csv(project_root/'data/raw/CMAPSSData/test_FD004.txt', sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Empty Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_FD001_data = train_FD001_data.dropna(axis=1, how='all')\n",
    "test_FD001_data = test_FD001_data.dropna(axis=1, how='all')\n",
    "train_FD002_data = train_FD002_data.dropna(axis=1, how='all')\n",
    "test_FD002_data = test_FD002_data.dropna(axis=1, how='all')\n",
    "train_FD003_data = train_FD003_data.dropna(axis=1, how='all')\n",
    "test_FD003_data = test_FD003_data.dropna(axis=1, how='all')\n",
    "train_FD004_data = train_FD004_data.dropna(axis=1, how='all')\n",
    "test_FD004_data = test_FD004_data.dropna(axis=1, how='all')\n",
    "\n",
    "print(train_FD001_data.isnull().sum())\n",
    "print(test_FD001_data.isnull().sum())\n",
    "print(train_FD002_data.isnull().sum())\n",
    "print(test_FD002_data.isnull().sum())\n",
    "print(train_FD003_data.isnull().sum())\n",
    "print(test_FD003_data.isnull().sum())\n",
    "print(train_FD004_data.isnull().sum())\n",
    "print(test_FD004_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add an extra column on each dataset with the RUL value on each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1       2       3      4       5       6        7        8      9  ...  \\\n",
      "0  1  1 -0.0007 -0.0004  100.0  518.67  641.82  1589.70  1400.60  14.62  ...   \n",
      "1  1  2  0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14  14.62  ...   \n",
      "2  1  3 -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20  14.62  ...   \n",
      "3  1  4  0.0007  0.0000  100.0  518.67  642.35  1582.79  1401.87  14.62  ...   \n",
      "4  1  5 -0.0019 -0.0002  100.0  518.67  642.37  1582.85  1406.22  14.62  ...   \n",
      "\n",
      "        17       18      19    20   21    22     23     24       25  RUL  \n",
      "0  2388.02  8138.62  8.4195  0.03  392  2388  100.0  39.06  23.4190  191  \n",
      "1  2388.07  8131.49  8.4318  0.03  392  2388  100.0  39.00  23.4236  190  \n",
      "2  2388.03  8133.23  8.4178  0.03  390  2388  100.0  38.95  23.3442  189  \n",
      "3  2388.08  8133.83  8.3682  0.03  392  2388  100.0  38.88  23.3739  188  \n",
      "4  2388.04  8133.80  8.4294  0.03  393  2388  100.0  38.90  23.4044  187  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "datasets = [train_FD001_data,train_FD002_data,train_FD003_data,train_FD004_data]\n",
    "sensor_start = 5\n",
    "sensor_end = 25\n",
    "\n",
    "for dataset in datasets:\n",
    "    unique_units = np.unique(dataset[0])\n",
    "    max_cycles = {unit: dataset[dataset[0] == unit][1].max() for unit in unique_units}\n",
    "    dataset['RUL'] = np.array([max_cycles[unit] - cycle for unit, cycle in zip(dataset[0], dataset[1])])\n",
    "\n",
    "print(train_FD001_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for train_FD001 and train_FD003 lets drop the sensors that have a correlation < 0.1 or NA with the RUL. Lets keep all sensor data for train_FD002 and train_FD004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = [test_FD001_data, test_FD003_data]\n",
    "\n",
    "for i, dataset in enumerate([train_FD001_data, train_FD003_data]):\n",
    "    features = dataset.iloc[:, 2:-1]\n",
    "    rul = dataset['RUL']\n",
    "    \n",
    "    correlations = abs(features.corrwith(rul))\n",
    "    \n",
    "    columns_to_drop = [sensor_idx for sensor_idx in correlations.index if correlations[sensor_idx] < 0.1 or pd.isna(correlations[sensor_idx])]\n",
    "    \n",
    "    dataset.drop(columns=columns_to_drop, inplace=True)\n",
    "    \n",
    "    test_dataset[i].drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that out of the way, lets normalize the remaining operational settings and sensor data.\n",
    "\n",
    "We will scale the RUL data in the modeling notebook for convenience as we will need the scaler instance when inverse scaling the predicted RUL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD001 - Scaled Training Data:\n",
      "   0  1         6         7         8        10        11        12        13  \\\n",
      "0  1  1 -1.721725 -0.134255 -0.925936  0.141683  1.121141 -0.516338 -0.862813   \n",
      "1  1  2 -1.061780  0.211528 -0.643726  0.141683  0.431930 -0.798093 -0.958818   \n",
      "2  1  3 -0.661813 -0.413166 -0.525953  0.141683  1.008155 -0.234584 -0.557139   \n",
      "3  1  4 -0.661813 -1.261314 -0.784831  0.141683  1.222827  0.188048 -0.713826   \n",
      "4  1  5 -0.621816 -1.251528 -0.301518  0.141683  0.714393 -0.516338 -0.457059   \n",
      "\n",
      "         15        16        17        18        19        21        24  \\\n",
      "0 -0.266467  0.334262 -1.058890 -0.269071 -0.603816 -0.781710  1.348493   \n",
      "1 -0.191583  1.174899 -0.363646 -0.642845 -0.275852 -0.781710  1.016528   \n",
      "2 -1.015303  1.364721 -0.919841 -0.551629 -0.649144 -2.073094  0.739891   \n",
      "3 -1.539489  1.961302 -0.224597 -0.520176 -1.971665 -0.781710  0.352598   \n",
      "4 -0.977861  1.052871 -0.780793 -0.521748 -0.339845 -0.136018  0.463253   \n",
      "\n",
      "         25  RUL  \n",
      "0  1.194427  191  \n",
      "1  1.236922  190  \n",
      "2  0.503423  189  \n",
      "3  0.777792  188  \n",
      "4  1.059552  187  \n",
      "FD001 - Scaled Test Data:\n",
      "   0   1         6         7         8         10        11        12  \\\n",
      "0   1   1  0.678077 -0.853550 -1.191480  0.141683  0.601408 -0.798093   \n",
      "1   1   2 -1.941707 -0.338137 -1.501467  0.141683  1.674769 -1.220725   \n",
      "2   1   3 -0.441831 -0.584426 -0.843717  0.141683  0.838677 -0.657216   \n",
      "3   1   4 -0.481827 -1.044384 -0.279297  0.141683  0.793483 -0.938970   \n",
      "4   1   5 -0.341839 -0.543650 -0.779276  0.141683  0.895170 -1.220725   \n",
      "\n",
      "         13        15        16        17        18        19        21  \\\n",
      "0 -0.682579 -1.277396  0.415614 -0.919841 -0.954235 -0.985107 -0.781710   \n",
      "1 -0.490117 -0.154141  1.012195 -0.502695 -0.216648 -1.649034 -0.136018   \n",
      "2 -0.375093 -0.154141  0.754581 -0.919841 -0.715712  0.052112 -0.136018   \n",
      "3 -0.903570 -0.977861 -0.045381 -0.641744 -0.568929 -1.345067 -1.427402   \n",
      "4 -0.937081 -0.865536  0.998637 -0.919841 -0.745069 -1.041101 -2.073094   \n",
      "\n",
      "         24        25  \n",
      "0  0.241943  0.774097  \n",
      "1  1.127183  0.941305  \n",
      "2  1.459148  1.172256  \n",
      "3  1.016528  0.775945  \n",
      "4  0.961200  1.138999  \n",
      "FD002 - Scaled Training Data:\n",
      "   0  1         2         3         4         5         6         7         8  \\\n",
      "0  1  1  0.745895  0.864298  0.418187 -0.889378 -0.653071 -0.579176 -0.572622   \n",
      "1  1  2  1.220553  0.866878  0.418187 -1.057627 -0.798422 -0.630051 -0.668741   \n",
      "2  1  3  0.067836  0.160457 -2.391275 -0.392968 -1.136055 -1.540521 -1.326301   \n",
      "3  1  4  1.221198  0.869459  0.418187 -1.057627 -0.808881 -0.622406 -0.663705   \n",
      "4  1  5  0.067951  0.155618 -2.391275 -0.392968 -1.142491 -1.531554 -1.322271   \n",
      "\n",
      "          9  ...        17        18        19        20        21        22  \\\n",
      "0 -0.706177  ...  0.415116 -0.212615  0.021948 -0.705933 -0.515579 -0.039954   \n",
      "1 -1.140622  ...  0.414648  0.067215  0.063719 -0.705933 -0.659701 -0.115645   \n",
      "2 -0.271732  ... -2.393490 -2.377822  2.087798 -0.705933 -1.416342 -2.159318   \n",
      "3 -1.140622  ...  0.414257  0.024309  0.030890 -0.705933 -0.695731 -0.115645   \n",
      "4 -0.271732  ... -2.393724 -2.420728  2.090734 -0.705933 -1.416342 -2.159318   \n",
      "\n",
      "         23        24        25  RUL  \n",
      "0  0.418187 -0.613958 -0.619148  148  \n",
      "1  0.418187 -1.051681 -1.048190  147  \n",
      "2 -2.391275 -0.679819 -0.641912  146  \n",
      "3  0.418187 -1.033443 -1.013808  145  \n",
      "4 -2.391275 -0.674753 -0.666180  144  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "FD002 - Scaled Test Data:\n",
      "   0   1         2         3         4         5         6         7   \\\n",
      "0   1   1 -0.949310 -1.038202  0.418187  0.611600  0.680028  0.728668   \n",
      "1   1   2 -0.270953  0.412704  0.418187  0.692693  0.754849  0.577930   \n",
      "2   1   3  0.746315  0.864298  0.418187 -0.889378 -0.634835 -0.574740   \n",
      "3   1   4  1.221123  0.867523  0.418187 -1.057627 -0.791181 -0.663370   \n",
      "4   1   5  0.067816  0.158844 -2.391275 -0.392968 -1.151877 -1.574312   \n",
      "\n",
      "         8         9   ...        16        17        18        19        20  \\\n",
      "0  0.835679  0.688475  ...  0.767270  0.418708  0.559923 -0.910220  1.416565   \n",
      "1  0.341397  0.364716  ...  0.357777  0.418240 -0.159573 -0.118978 -0.705933   \n",
      "2 -0.647083 -0.706177  ... -0.603153  0.415351 -0.159808  0.023416 -0.705933   \n",
      "3 -0.651028 -1.140622  ... -0.985550  0.415116  0.003564  0.088675 -0.705933   \n",
      "4 -1.299102 -0.271732  ... -0.737399 -2.393334 -2.368510  2.053234 -0.705933   \n",
      "\n",
      "         21        22        23        24        25  \n",
      "0  0.745489  0.620627  0.418187  0.773181  0.790616  \n",
      "1  0.565336  0.655032  0.418187  0.354709  0.393558  \n",
      "2 -0.551609 -0.039954  0.418187 -0.588627 -0.601349  \n",
      "3 -0.587640 -0.115645  0.418187 -1.057761 -1.022589  \n",
      "4 -1.560464 -2.159318 -2.391275 -0.656514 -0.658513  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "FD003 - Scaled Training Data:\n",
      "   0  1         6         7         8        10        11        12        13  \\\n",
      "0  1  1 -0.187102 -0.712038 -0.780848  0.781589 -0.341494 -0.704785 -0.097138   \n",
      "1  1  2  0.080574 -0.497656 -0.775732  0.781589 -0.172755 -0.452071 -0.116658   \n",
      "2  1  3 -0.531256 -0.841254  0.116524  0.781589 -0.207667 -0.262536  0.306267   \n",
      "3  1  4  0.883602 -0.362566 -1.248464  0.781589  0.019257 -0.452071  0.022983   \n",
      "4  1  5 -1.487242  0.080881 -0.697966  0.781589 -0.117479 -0.199357  0.602065   \n",
      "\n",
      "         14        15        16        17        18        21  RUL  \n",
      "0 -0.353479 -0.385602 -0.227593 -0.389857  0.067687 -0.889364  258  \n",
      "1 -0.353479 -0.618882 -0.193802 -0.263369  0.523946 -0.321641  257  \n",
      "2 -0.353479 -0.652208 -0.313608 -0.453101  0.361559 -0.889364  256  \n",
      "3 -0.353479 -0.585556 -0.172298  0.052852  0.142821 -0.321641  255  \n",
      "4 -0.353479 -0.885488 -0.144650 -0.263369  0.217955 -0.321641  254  \n",
      "FD003 - Scaled Test Data:\n",
      "   0   1         6         7         8         10        11        12  \\\n",
      "0   1   1 -0.990129 -0.902925 -0.771639 -0.874439 -0.169846 -0.894321   \n",
      "1   1   2 -0.837172 -0.472693 -0.570063 -0.874439 -0.303673 -0.831142   \n",
      "2   1   3 -1.487242 -0.924951 -1.284277 -0.874439 -0.213485 -0.641607   \n",
      "3   1   4 -0.493017 -0.521150 -0.934332 -0.322430 -0.164028 -0.831142   \n",
      "4   1   5  0.004095  0.139616 -0.881124 -0.874439 -0.286218 -0.388893   \n",
      "\n",
      "         13        14        15        16        17        18        21  \n",
      "0 -0.773819 -0.353479 -1.085443 -0.356616 -0.832566 -0.649725 -0.889364  \n",
      "1 -0.879925 -0.353479 -1.118768 -0.368904 -0.389857 -0.409780 -0.889364  \n",
      "2 -0.460003 -0.353479 -0.885488 -0.292104 -0.832566 -0.360700 -0.889364  \n",
      "3 -0.453997 -0.353479 -0.518905 -0.184586 -0.706078 -0.432199 -0.321641  \n",
      "4 -0.776822 -0.353479 -1.585329 -0.350472 -0.642833 -0.606098 -0.889364  \n",
      "FD004 - Scaled Training Data:\n",
      "   0  1         2         3         4         5         6         7         8  \\\n",
      "0  1  1  1.218156  0.864668  0.418783 -1.054690 -0.796416 -0.701412 -0.745729   \n",
      "1  1  2 -0.270478  0.414718  0.418783  0.692508  0.713666  0.562449  0.298212   \n",
      "2  1  3  1.218082  0.867565  0.418783 -1.054690 -0.815965 -0.704332 -0.711202   \n",
      "3  1  4  1.217824  0.864668  0.418783 -1.054690 -0.822660 -0.722040 -0.702990   \n",
      "4  1  5  0.068094  0.158844 -2.387873 -0.391216 -1.160079 -1.532181 -1.410627   \n",
      "\n",
      "          9  ...        17        18        19        20        21        22  \\\n",
      "0 -1.137677  ...  0.417814  0.081921  0.063831 -0.694278 -0.638665 -0.114203   \n",
      "1  0.363906  ...  0.415786 -0.253086 -0.125677 -0.694278  0.476120  0.655708   \n",
      "2 -1.137677  ...  0.417658 -0.013912  0.153387 -0.694278 -0.674626 -0.114203   \n",
      "3 -1.137677  ...  0.418048  0.096162  0.068362 -0.694278 -0.710586 -0.114203   \n",
      "4 -0.270955  ... -2.389666 -2.358027  2.066982 -0.694278 -1.537685 -2.155843   \n",
      "\n",
      "         23        24        25  RUL  \n",
      "0  0.418783 -1.030999 -1.031756  320  \n",
      "1  0.418783  0.352814  0.358264  319  \n",
      "2  0.418783 -1.045089 -1.022649  318  \n",
      "3  0.418783 -1.039051 -1.023269  317  \n",
      "4 -2.387873 -0.687814 -0.644612  316  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "FD004 - Scaled Test Data:\n",
      "   0   1         2         3         4         5         6         7   \\\n",
      "0   1   1 -0.270126  0.414074  0.418783  0.692508  0.729733  0.594757   \n",
      "1   1   2  0.067560  0.156591 -2.387873 -0.391216 -1.156865 -1.523327   \n",
      "2   1   3  1.217824  0.871105  0.418783 -1.054690 -0.808467 -0.732495   \n",
      "3   1   4  1.218061  0.865312  0.418783 -1.054690 -0.809538 -0.736545   \n",
      "4   1   5  0.744765  0.864668  0.418783 -0.886741 -0.651273 -0.610894   \n",
      "\n",
      "         8         9   ...        16        17        18        19        20  \\\n",
      "0  0.217006  0.363906  ...  0.334308  0.416176 -0.219818 -0.083564 -0.694278   \n",
      "1 -1.428310 -0.270955  ... -0.744708 -2.389588 -2.385341  2.102432 -0.694278   \n",
      "2 -0.804811 -1.137677  ... -0.987563  0.417502  0.038732  0.147123 -0.694278   \n",
      "3 -0.793246 -1.137677  ... -0.991173  0.417112  0.129313  0.098347 -0.694278   \n",
      "4 -0.704917 -0.704316  ... -0.613207  0.416878 -0.116515  0.023184 -0.694278   \n",
      "\n",
      "         21        22        23        24        25  \n",
      "0  0.512081  0.655708  0.418783  0.346775  0.365895  \n",
      "1 -1.501724 -2.155843 -2.387873 -0.654602 -0.661484  \n",
      "2 -0.710586 -0.114203  0.418783 -1.054147 -1.020100  \n",
      "3 -0.710586 -0.114203  0.418783 -1.037038 -1.053608  \n",
      "4 -0.530782 -0.038587  0.418783 -0.605288 -0.601477  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create separate scalers for each dataset\n",
    "FD001_scaler = StandardScaler()\n",
    "FD002_scaler = StandardScaler()\n",
    "FD003_scaler = StandardScaler()\n",
    "FD004_scaler = StandardScaler()\n",
    "\n",
    "# Map datasets to their respective scalers\n",
    "dataset_scaler_map = {\n",
    "    \"FD001\": (train_FD001_data, test_FD001_data, FD001_scaler),\n",
    "    \"FD002\": (train_FD002_data, test_FD002_data, FD002_scaler),\n",
    "    \"FD003\": (train_FD003_data, test_FD003_data, FD003_scaler),\n",
    "    \"FD004\": (train_FD004_data, test_FD004_data, FD004_scaler),\n",
    "}\n",
    "\n",
    "# Scale each dataset separately\n",
    "for dataset_name, (train_data, test_data, scaler) in dataset_scaler_map.items():\n",
    "    # Process training data\n",
    "    features_train = train_data.iloc[:, 2:-1]  # Exclude first two columns (engine ID, time step) and last column (RUL)\n",
    "    target_train = train_data.iloc[:, -1]  # Extract the RUL column\n",
    "\n",
    "    # Scale and replace features in the training dataset\n",
    "    train_data.iloc[:, 2:-1] = scaler.fit_transform(features_train)\n",
    "    train_data.iloc[:, -1] = target_train  # Re-attach the unscaled RUL column\n",
    "\n",
    "    # Process test data (no RUL column in test data)\n",
    "    features_test = test_data.iloc[:, 2:]  # Exclude only the first two columns (engine ID, time step)\n",
    "    test_data.iloc[:, 2:] = scaler.transform(features_test)\n",
    "\n",
    "    # Verify scaling\n",
    "    print(f\"{dataset_name} - Scaled Training Data:\")\n",
    "    print(train_data.head())\n",
    "    print(f\"{dataset_name} - Scaled Test Data:\")\n",
    "    print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Cleaned Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_FD001_data.to_csv(project_root/'data/processed/train_FD001.csv', index=False)\n",
    "test_FD001_data.to_csv(project_root/'data/processed/test_FD001.csv', index=False)\n",
    "\n",
    "train_FD002_data.to_csv(project_root/'data/processed/train_FD002.csv', index=False)\n",
    "test_FD002_data.to_csv(project_root/'data/processed/test_FD002.csv', index=False)\n",
    "\n",
    "train_FD003_data.to_csv(project_root/'data/processed/train_FD003.csv', index=False)\n",
    "test_FD003_data.to_csv(project_root/'data/processed/test_FD003.csv', index=False)\n",
    "\n",
    "train_FD004_data.to_csv(project_root/'data/processed/train_FD004.csv', index=False)\n",
    "test_FD004_data.to_csv(project_root/'data/processed/test_FD004.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me371",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
